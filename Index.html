<style>
  body,
  html {
    margin: 0;
    padding: 0;
    width: 100%;
    height: 100%;
    overflow: hidden;
    display: flex;
    justify-content: center;
    align-items: center;
  }

  .final_canvas {
    width: 100%;
    height: 100%;
    object-fit: cover;
    object-position: center;
    position: absolute;
    left: 0;
    top: 0;
    transform: rotateY(180deg);
    -webkit-transform: rotateY(180deg);
    -moz-transform: rotateY(180deg);
  }

  video {
    clear: both;
    /* display: block; */
    transform: rotateY(180deg);
    -webkit-transform: rotateY(180deg);
    -moz-transform: rotateY(180deg);
  }

  .canvas {
    z-index: 1;
    position: relative;
    pointer-events: none;
  }

  .output_canvas {
    transform: rotateY(180deg);
    -webkit-transform: rotateY(180deg);
    -moz-transform: rotateY(180deg);
  }

  #liveView {
    position: relative;
    width: 100%;
    height: 100%;
  }

  video,
  canvas {
    width: 100%;
    height: 100%;
    position: absolute;
    left: 0;
    top: 0;
  }
</style>

<body>

  <video id="webcam" style="width: 1280x; height: 720px; position: absolute; left: 0px; top: 0px;" autoplay
    playsinline></video>
  <canvas class="output_canvas" id="output_canvas" width="1280px" height="720px"
    style="position: absolute; left: 0px; top: 0px;"></canvas>
  <canvas class="final_canvas" id="final_canvas"></canvas>

  <script type="module">

    // import {
    //     PoseLandmarker,
    //     FilesetResolver,
    //     DrawingUtils
    // } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.17";

    async function loadPoseLandmarker() {
      let PoseLandmarker, FilesetResolver, DrawingUtils;

      try {
        ({ PoseLandmarker, FilesetResolver, DrawingUtils } = await import("https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.17"));
        console.log("Task 1: Loaded from Skypack");
      } catch (e) {
        ({ PoseLandmarker, FilesetResolver, DrawingUtils } = await import("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.17"));
        console.log("Task 1: Loaded from jsDelivr");
      }

      return { PoseLandmarker, FilesetResolver, DrawingUtils };
    }

    let poseLandmarker = undefined;
    let runningMode = "VIDEO";
    let webcamRunning = true;

    loadPoseLandmarker().then(({ PoseLandmarker, FilesetResolver, DrawingUtils }) => {
      // Before we can use PoseLandmarker class we must wait for it to finish
      // loading. Machine Learning models can be large and take a moment to
      // get everything needed to run.
      const createPoseLandmarker = async () => {
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.17/wasm"
        );
        poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/latest/pose_landmarker_heavy.task`,
            delegate: "GPU"
          },
          runningMode: runningMode,
          numPoses: 1,
          minPoseDetectionConfidence: 0.4,
          minPosePresenceConfidence: 0.5,
          minPoseTrackingConfidence: 0.54,
          outputSegmentationMasks: false,
        });
      };
      createPoseLandmarker();
      console.log("PoseLandmarker is loading...");


      /********************************************************************
      Continuously grab image from webcam stream and detect it.
      ********************************************************************/

      const video = document.getElementById("webcam");
      // turn off display of video element
      video.style.display = "none";
      const canvasElement = document.getElementById("output_canvas");
      const canvasCtx = canvasElement.getContext("2d");
      const drawingUtils = new DrawingUtils(canvasCtx);
      // trun off display of canvas element
      canvasElement.style.display = "none";
      // Create a canvas element to display the final output.
      const finalCanvasElement = document.getElementById("final_canvas");
      const finalCanvasCtx = finalCanvasElement.getContext("2d");
      finalCanvasElement.style.display = "block";
      adjustCanvasSize();

      // define a variable for the detection to wait 5 seconds before starting
      let waitTime = 5000;

      // Check if webcam access is supported.
      const hasGetUserMedia = () => !!navigator.mediaDevices?.getUserMedia;

      // If webcam supported, add event listener to button for when user
      // wants to activate it.
      if (hasGetUserMedia()) {
        enableCam();
      } else {
        console.warn("getUserMedia() is not supported by your browser");
      }

      // Enable the live webcam view and start detection.
      function enableCam(event) {

        // getUsermedia parameters.
        const constraints = {
          video: true
        };

        // Activate the webcam stream.
        navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
          // get width and height of video stream
          const videoHeight = stream.getVideoTracks()[0].getSettings().height;
          const videoWidth = stream.getVideoTracks()[0].getSettings().width;
          window.videoHeight = videoHeight;
          window.videoWidth = videoWidth;
          video.srcObject = stream;
          video.addEventListener("loadeddata", predictWebcam);
        });
      }

      let lastVideoTime = -1;
      async function predictWebcam() {
        canvasElement.style.height = videoHeight;
        video.style.height = videoHeight;
        canvasElement.style.width = videoWidth;
        video.style.width = videoWidth;
        // Now let's start detecting the stream.
        if (runningMode === "IMAGE") {
          runningMode = "VIDEO";
          await poseLandmarker.setOptions({ runningMode: "VIDEO" });
        }
        let startTimeMs = performance.now();
        
        if (startTimeMs < waitTime) {
          // console.log("waiting...");
          return;
        }

        if (lastVideoTime !== video.currentTime) {
          lastVideoTime = video.currentTime;
          poseLandmarker.detectForVideo(video, startTimeMs, (result) => {
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            for (const landmark of result.landmarks) {
              // console.log(landmark);
              drawingUtils.drawLandmarks(landmark, {
                radius: (data) => DrawingUtils.lerp(data.from.z, -0.15, 0.1, 5, 1)
              });
              drawingUtils.drawConnectors(landmark, PoseLandmarker.POSE_CONNECTIONS);
            }
            canvasCtx.restore();

            // Draw the final canvas.
            finalCanvasCtx.save();
            finalCanvasCtx.clearRect(0, 0, finalCanvasElement.width, finalCanvasElement.height);
            finalCanvasCtx.drawImage(video, 0, 0, finalCanvasElement.width, finalCanvasElement.height);
            finalCanvasCtx.drawImage(canvasElement, 0, 0, finalCanvasElement.width, finalCanvasElement.height);
            finalCanvasCtx.restore();

          });
        }

        // Call this function again to keep predicting when the browser is ready.
        if (webcamRunning === true) {
          window.requestAnimationFrame(predictWebcam);
        }
      }
      function adjustCanvasSize() {
        const width = window.innerWidth;
        const height = window.innerHeight;
        finalCanvasElement.width = width;
        finalCanvasElement.height = height;
      }

      // window.addEventListener('resize', adjustCanvasSize);
    });
  </script>
</body>